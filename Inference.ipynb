{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference with the trained Word2Num Model"
      ],
      "metadata": {
        "id": "o6zQsDA5xl8_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS__io-YxdE4"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bpemb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZvTUDPSx0vV",
        "outputId": "7a5b169e-673f-4431-b089-c6c4d9545bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bpemb\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb) (2.23.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from bpemb) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bpemb) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.7.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2022.6.15)\n",
            "Installing collected packages: sentencepiece, bpemb\n",
            "Successfully installed bpemb-0.3.3 sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhoKpCBmx4L4",
        "outputId": "2dfa1843-36bf-43cf-d0b2-8069c9419f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bpemb import BPEmb\n",
        "\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "BPEMB_HI = BPEmb(lang=\"hi\", vs=25000, dim=100)\n",
        "SRC_BPE_WEIGHTS = torch.tensor(BPEMB_HI.vectors)\n",
        "SRC_VOCAB_SIZE = SRC_BPE_WEIGHTS.shape[0]\n",
        "TGT_VOCAB_SIZE = 14\n",
        "EMB_SIZE = 100\n",
        "NHEAD = 4\n",
        "FFN_HID_DIM = 512\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "\n",
        "\n",
        "def row_processer_inp(input):\n",
        "    X = input\n",
        "    return re.sub(',', '', re.sub('-', ' ', X.strip()))\n",
        "\n",
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int=None, emb_size=None, weights=None):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        if weights is not None:            \n",
        "            self.embedding = nn.Embedding.from_pretrained(weights)\n",
        "            self.emb_size = weights.shape[1]\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "            self.emb_size = emb_size\n",
        "    \n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network \n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1,\n",
        "                 src_bpe_weights = None):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        if src_bpe_weights is not None:\n",
        "            self.src_tok_emb = TokenEmbedding(weights=src_bpe_weights)\n",
        "        else:\n",
        "            self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, \n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)\n",
        "\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
        "\n",
        "def token_transform(x):\n",
        "    return BPEMB_HI.encode_ids(x)\n",
        "\n",
        "def tensor_transform_src(token_ids):\n",
        "    return torch.tensor(token_ids)\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        num = 0\n",
        "        for transform in transforms:\n",
        "            if num != 0:\n",
        "                txt_input = [item for sublist in txt_input for item in sublist]\n",
        "                a = np.array(txt_input).reshape(len(txt_input),1)\n",
        "                txt_input = list(map(list, a))\n",
        "                    \n",
        "            txt_input = transform(txt_input)\n",
        "            num = 1\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to generate output sequence using greedy algorithm \n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "# %%\n",
        "# actual function to translate input sentence into target language\n",
        "class NumberModel:\n",
        "\n",
        "\n",
        "  \n",
        "    def __init__(self, PATH):\n",
        "        #Load the model here\n",
        "\n",
        "        self.transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, \n",
        "                                    NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM, src_bpe_weights=SRC_BPE_WEIGHTS)\n",
        "        self.transformer.load_state_dict(torch.load(PATH))\n",
        "        self.transformer.to(DEVICE)\n",
        "        \n",
        "\n",
        "    def translate(self, model: torch.nn.Module, src_sentence: str):\n",
        "        idx2class = dict(zip(list(range(14)), ['<unk>', '<pad>', '<bos>', '<eos>', '7', '2', '5', '4', '8', '3', '0', '1', '9', '6']))\n",
        "        get_cls_preds = lambda x: [idx2class[i] for i in x]\n",
        "        model.eval()\n",
        "\n",
        "        text_transform = sequential_transforms(\n",
        "                        token_transform, #Tokenization\n",
        "                        tensor_transform_src) \n",
        "        src = text_transform(src_sentence.split()).view(-1, 1)\n",
        "        num_tokens = src.shape[0]\n",
        "        src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "        tgt_tokens = greedy_decode(\n",
        "            model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "        return \"\".join(get_cls_preds(tgt_tokens.cpu().numpy())).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "\n",
        "    def inference(self, text):\n",
        "        #Call the inference model here\n",
        "        digits = self.translate(self.transformer, text)\n",
        "        return digits"
      ],
      "metadata": {
        "id": "qHpCWg9gxxwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/model_emb.pth\"\n",
        "\n",
        "text = \"पाँच सौ अट्ठारह \"\n",
        "number_model = NumberModel(PATH)\n",
        "text = number_model.inference(text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3wEjqc9XTCq",
        "outputId": "1cd2458b-5115-404f-a874-fa289c0b7eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "def read_data(data):\n",
        "    # open .tsv file\n",
        "    with open(data, 'r', encoding=\"utf-8\") as file:\n",
        "        tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
        "        X_train = []\n",
        "        y_train = []\n",
        "        for line in tsv_file:\n",
        "            X_train.append(line[0])\n",
        "            y_train.append(line[1])\n",
        "\n",
        "    return X_train, y_train"
      ],
      "metadata": {
        "id": "zys5X0KPMXbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, \n",
        "                                    NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM, src_bpe_weights=SRC_BPE_WEIGHTS)\n",
        "transformer.load_state_dict(torch.load(\"model_emb.pth\"))\n",
        "transformer.to(DEVICE)\n",
        "\n",
        "X_test, y_test = read_data(\"benchmark.tsv\")\n",
        "\n",
        "cnt_corr = 0\n",
        "for i in tqdm(range(len(X_test))):\n",
        "    pred = translate(transformer, row_processer_inp(X_test[i]))\n",
        "    true = y_test[i]\n",
        "    if pred == true:\n",
        "        cnt_corr += 1\n",
        "    else:\n",
        "        print(X_test[i])\n",
        "        print(pred)\n",
        "        print(true)\n",
        "\n",
        "print(\"Accuracy on test set: \", cnt_corr/len(X_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haW49qz9MC-g",
        "outputId": "7bb8a799-b36e-45cf-a8bd-2c9e3561ea5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 172/200 [00:04<00:00, 40.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "नौ दो पाँच सात सौ छः छः\n",
            "9257066\n",
            "92570066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:05<00:00, 38.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set:  0.995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nm9YU--bRmyk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}